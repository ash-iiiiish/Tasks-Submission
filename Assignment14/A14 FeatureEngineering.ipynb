{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c1074bd",
   "metadata": {},
   "source": [
    "# Part1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ec712",
   "metadata": {},
   "source": [
    "# Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e03eff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Age Group\n",
    "df[\"age_group\"] = pd.cut(\n",
    "    df[\"age\"],\n",
    "    bins=[0, 12, 18, 35, 60, 100],\n",
    "    labels=[\"Child\", \"Teen\", \"Adult\", \"Senior\"]\n",
    ")\n",
    "\n",
    "# 2. Family Size\n",
    "df[\"family_size\"] = df[\"sibsp\"] + df[\"parch\"] + 1\n",
    "\n",
    "# 3. Fare per Person\n",
    "df[\"fare_per_person\"] = df[\"fare\"] / df[\"family_size\"]\n",
    "\n",
    "df[[\"age\", \"age_group\", \"family_size\", \"fare_per_person\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b29c98",
   "metadata": {},
   "source": [
    "# Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738c24d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to datetime\n",
    "df[\"order_date\"] = pd.to_datetime(df[\"order_date\"])\n",
    "\n",
    "# Extract year, month, day\n",
    "df[\"order_year\"] = df[\"order_date\"].dt.year\n",
    "df[\"order_month\"] = df[\"order_date\"].dt.month\n",
    "df[\"order_day\"] = df[\"order_date\"].dt.day\n",
    "\n",
    "# Text feature: word count\n",
    "df[\"review_length\"] = df[\"review_text\"].astype(str).apply(len)\n",
    "df[\"review_word_count\"] = df[\"review_text\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "df[[\"order_date\", \"order_year\", \"order_month\", \"order_day\",\n",
    "    \"review_length\", \"review_word_count\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec9b20",
   "metadata": {},
   "source": [
    "# Part2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6851e6e",
   "metadata": {},
   "source": [
    "# Task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e9fedd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "\n",
    "df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "df_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d98625",
   "metadata": {},
   "source": [
    "# Task4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b6f11",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "num_cols = df.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "        (\"cat\", OneHotEncoder(drop=\"first\"), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_transformed = preprocessor.fit_transform(df)\n",
    "df_transformed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e80e360",
   "metadata": {},
   "source": [
    "# Part3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb999d7",
   "metadata": {},
   "source": [
    "# Task5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ecdd49",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "df_scaled[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73492981",
   "metadata": {},
   "source": [
    "# Task6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91653550",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "df_minmax = minmax.fit_transform(df[num_cols])\n",
    "\n",
    "df_minmax[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4a85b5",
   "metadata": {},
   "source": [
    "# Part4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f76e13",
   "metadata": {},
   "source": [
    "# Task7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1aed8e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"encoder\", OneHotEncoder(drop=\"first\"))\n",
    "])\n",
    "\n",
    "full_preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_cols),\n",
    "    (\"cat\", cat_pipeline, cat_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81b630c",
   "metadata": {},
   "source": [
    "# Task8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517ce8ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(\"survived\", axis=1)\n",
    "y = df[\"survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    (\"preprocessing\", full_preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21028cd4",
   "metadata": {},
   "source": [
    "# Task9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196cd988",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_cols),\n",
    "    (\"cat\", cat_pipeline, cat_cols)\n",
    "])\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(\"survived\", axis=1)\n",
    "y = df[\"survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = full_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Pipeline Accuracy:\", full_pipeline.score(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
